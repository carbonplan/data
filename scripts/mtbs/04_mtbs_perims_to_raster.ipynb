{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"50\" src=\"https://carbonplan-assets.s3.amazonaws.com/monogram/dark-small.png\" style=\"margin-left:0px;margin-top:20px\"/>\n",
    "\n",
    "# MTBS Perimeters to Zarr\n",
    "\n",
    "_by Joe Hamman (CarbonPlan), November 3, 2020_\n",
    "\n",
    "This notebook converts MTBS fire perimeters to monthly burned area rasters\n",
    "\n",
    "**Inputs:**\n",
    "\n",
    "- MTBS fire perimeters shapefile\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "- 1 Zarr archive:\n",
    "  `gs://carbonplan-data/processed/mtbs/conus/{res}m/monthly_perims_raster.zarr`\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "- Text defining large and very large fires from Barbero et al. (2015):\n",
    "  > The Monitoring Trends in Burn Severity (MTBS) data- base was used to acquire\n",
    "  > fire location, fire discovery date and burned area for LFs over the\n",
    "  > contiguous US from 1984 to 2010. We excluded fires smaller than 404ha and\n",
    "  > further eliminated 'unburned to low' burned area for each fire as classified\n",
    "  > by MTBS to more accurately portray the true area burned (Kolden et al 2012).\n",
    "  > While the definition of VLFs is subjective and likely geographically\n",
    "  > dependent, we define VLFs as fires whose size exceeds the 90th percentile\n",
    "  > (5073 ha) of MTBS fires greater than 404 ha (n = 927) (figure 1(b)) and LF\n",
    "  > as fires whose size was below the 90th percentile but greater than 404 ha (n\n",
    "  > = 8343)(figure 1(c)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carbonplan.data import cat\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import geopandas\n",
    "\n",
    "import rasterio\n",
    "from rasterio import Affine\n",
    "from rasterio.transform import rowcol\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_bounds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import zarr\n",
    "\n",
    "import hvplot.pandas  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = pd.date_range(\"1984-01\", \"2018-12\", freq=\"MS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = cat.nlcd.raster.read().squeeze(drop=True)\n",
    "\n",
    "region = \"conus\"\n",
    "\n",
    "mask = rasterio.open(cat.mtbs.raw_raster._urlpath)\n",
    "transform = mask.transform\n",
    "shape = mask.shape\n",
    "src_profile = mask.profile\n",
    "\n",
    "# TODO: replace with intake use\n",
    "perims = geopandas.GeoDataFrame.from_file(\n",
    "    \"mtbs_perimeter_data/mtbs_perims_DD/mtbs_perims_DD.shp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note we set all start days to 1 (so we can easily group by month later)\n",
    "dates = pd.DatetimeIndex(\n",
    "    [pd.to_datetime(f\"{r.Year}-{r.StartMonth}-1\") for _, r in perims.iterrows()]\n",
    ")\n",
    "perims.index = dates\n",
    "perims = perims.sort_index()\n",
    "perims[\"ha\"] = perims[\"Acres\"] * 0.40468564224\n",
    "perims[\"ym\"] = dates\n",
    "perims = perims.to_crs(crs=mask.crs)\n",
    "perims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"Wild*|Out*|Unknown|Complex\"\n",
    "perims = perims[perims.Fire_Type.str.contains(pattern)]\n",
    "\n",
    "perims_lf = perims[perims.ha.between(404, 5073)]\n",
    "perims_vlf = perims[perims.ha > 5073]\n",
    "perims_vlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasterize_geom(geoms):\n",
    "\n",
    "    r = rasterize(\n",
    "        [(geom, 1) for geom in geoms],\n",
    "        out_shape=shape,\n",
    "        transform=transform,\n",
    "        fill=0,\n",
    "        merge_alg=rasterio.enums.MergeAlg.replace,\n",
    "        all_touched=True,\n",
    "        dtype=rasterio.uint8,\n",
    "    )\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perims_vlf[[\"ha\", \"geometry\", \"ym\"]][\"2018\":\"2018\"].to_crs(\"EPSG:4326\").hvplot(\n",
    "    c=\"ha\", geo=True, coastline=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rio_cogeo.profiles import cog_profiles\n",
    "from rasterio.io import MemoryFile\n",
    "from rio_cogeo.cogeo import cog_translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcsfs import GCSFileSystem\n",
    "\n",
    "\n",
    "def copy_to_fs(source, dst, fs):\n",
    "\n",
    "    with open(source, \"rb\") as fsource:\n",
    "        with fs.open(dst, \"wb\") as fdst:\n",
    "            fdst.write(fsource.read())\n",
    "\n",
    "\n",
    "def numpy_to_cog(data, out_fname=\"temp_cog.tif\"):\n",
    "    with MemoryFile() as memfile:\n",
    "        with memfile.open(**src_profile) as mem:\n",
    "            # Populate the input file with numpy array\n",
    "            mem.write(r, indexes=1)\n",
    "\n",
    "            dst_profile = cog_profiles.get(\"deflate\")\n",
    "            cog_translate(\n",
    "                mem,\n",
    "                out_fname,\n",
    "                dst_profile,\n",
    "                in_memory=True,\n",
    "                quiet=True,\n",
    "            )\n",
    "\n",
    "\n",
    "fs = GCSFileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unocomment to start over\n",
    "# paths = fs.glob('carbonplan-data/processed/mtbs/conus/30m/*f_????.??.tif')\n",
    "# fs.rm(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an empty file we can copy to each month without any fires\n",
    "r = np.zeros(shape, dtype=rasterio.uint8)\n",
    "numpy_to_cog(r, \"empty_cog.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_profile = cog_profiles.get(\"deflate\")\n",
    "\n",
    "for month in months:\n",
    "\n",
    "    for name, df in [(\"lf\", perims_lf), (\"vlf\", perims_vlf)]:\n",
    "\n",
    "        out_fname = f\"carbonplan-data/processed/mtbs/{region}/30m/{name}_{month.strftime('%Y.%m')}.tif\"\n",
    "\n",
    "        if fs.exists(out_fname):\n",
    "            print(f\"{out_fname} exists, skipping...\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            geom = df.loc[[month]].geometry\n",
    "            print(geom)\n",
    "            print(f\"rasterizing {month}\")\n",
    "            r = rasterize_geom(geom)\n",
    "            numpy_to_cog(r, \"temp_cog.tif\")\n",
    "            copy_to_fs(\"temp_cog.tif\", out_fname, fs)\n",
    "        except (KeyError, ValueError) as e:\n",
    "            print(f\"raised error: {e}\")\n",
    "            print(f\"copying empty cog to {out_fname}\")\n",
    "            copy_to_fs(\"empty_cog.tif\", out_fname, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import xarray as xr\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "cat2 = intake.open_catalog(\n",
    "    \"https://raw.githubusercontent.com/carbonplan/data/master/carbonplan_data/catalogs/mtbs.yaml\"\n",
    ")\n",
    "dates = [f\"2018.{m:02d}\" for m in range(1, 13)]\n",
    "da = xr.concat(\n",
    "    [\n",
    "        cat2.rasterized_perims(size=\"vlf\", date=d).to_dask().squeeze(drop=True)\n",
    "        for d in dates\n",
    "    ],\n",
    "    dim=xr.Variable(\"time\", dates),\n",
    ")\n",
    "\n",
    "with ProgressBar():\n",
    "    da_sum = da.sum(\"time\").coarsen(x=133, y=133, boundary=\"trim\").mean().load()\n",
    "da_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_sum.where(da_sum).plot(vmax=0.01, vmin=0, cmap=\"Greys\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
