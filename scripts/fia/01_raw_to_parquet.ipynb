{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"50\" src=\"https://carbonplan-assets.s3.amazonaws.com/monogram/dark-small.png\" style=\"margin-left:0px;margin-top:20px\"/>\n",
    "\n",
    "# FIA to Parquet\n",
    "\n",
    "_by Joe Hamman (CarbonPlan), June 30, 2020_\n",
    "\n",
    "This notebook converts FIA csv files to Parquet format and stages them in a\n",
    "Google Cloud Storage bucket.\n",
    "\n",
    "**Inputs:**\n",
    "\n",
    "- `ENTIRE` directory\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "- One Parquet dataset per CSV: `gs://carbonplan-data/raw/fia/<name>.parquet`\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "- No reprojection or processing of the data is done in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os.path\n",
    "import pathlib\n",
    "\n",
    "import gcsfs\n",
    "import pandas as pd\n",
    "\n",
    "# run `gcloud auth login` on the command line, or try switching token to `browser`\n",
    "fs = gcsfs.GCSFileSystem(\n",
    "    project=\"carbonplan\",\n",
    "    token=\"/Users/jhamman/.config/gcloud/legacy_credentials/joe@carbonplan.org/adc.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = pathlib.Path(\"/Users/jhamman/workdir/carbonplan_data_downloads/fia/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = (workdir / \"ENTIRE\").glob(\"*csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def force_float32(fname):\n",
    "\n",
    "    memmap = fname.stat().st_size > 1e8\n",
    "\n",
    "    df = pd.read_csv(fname, engine=\"c\", low_memory=False, memory_map=memmap)\n",
    "    for c in df:\n",
    "        if \"f8\" in df[c].dtype.str:\n",
    "            df[c] = df[c].astype(np.float32)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = []\n",
    "for fname in csvs:\n",
    "    blob = f\"carbonplan-data/raw/fia/{fname.stem}.parquet\"\n",
    "    print(fname)\n",
    "\n",
    "    df = force_float32(fname)\n",
    "\n",
    "    try:\n",
    "        df.to_parquet(\n",
    "            blob, compression=\"gzip\", open_with=fs.open, row_group_offsets=1000\n",
    "        )\n",
    "        # consider using dask dataframe here to write to chunked dataframes here.\n",
    "        print(\"  --> \", blob)\n",
    "    except:\n",
    "        failed.append(fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
