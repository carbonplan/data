{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"50\" src=\"https://carbonplan-assets.s3.amazonaws.com/monogram/dark-small.png\" style=\"margin-left:0px;margin-top:20px\"/>\n",
    "\n",
    "# FIA to Parquet\n",
    "\n",
    "_by Joe Hamman (CarbonPlan), June 30, 2020_\n",
    "\n",
    "This notebook converts FIA csv files to Parquet format and stages them in a\n",
    "Google Cloud Storage bucket.\n",
    "\n",
    "**Inputs:**\n",
    "\n",
    "- `ENTIRE` directory\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "- One Parquet dataset per CSV: `gs://carbonplan-data/raw/fia/<name>.parquet`\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "- No reprojection or processing of the data is done in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os.path\n",
    "import pathlib\n",
    "\n",
    "import gcsfs\n",
    "import pandas as pd\n",
    "\n",
    "from carbonplan_data.utils import setup\n",
    "\n",
    "# run `gcloud auth login` on the command line, or try switching token to `browser`\n",
    "fs = gcsfs.GCSFileSystem(\n",
    "    project=\"carbonplan\",\n",
    "    token=\"/Users/jhamman/.config/gcloud/legacy_credentials/joe@carbonplan.org/adc.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir, upload = setup(\"joe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = (workdir / \"fia/ENTIRE\").glob(\"*csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def force_float32(fname):\n",
    "\n",
    "    memmap = fname.stat().st_size > 1e8\n",
    "\n",
    "    df = pd.read_csv(fname, engine=\"c\", low_memory=False, memory_map=memmap)\n",
    "    for c in df:\n",
    "        if \"f8\" in df[c].dtype.str:\n",
    "            df[c] = df[c].astype(np.float32)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(blob):\n",
    "    try:\n",
    "        f = fs.open(blob, \"rb\")\n",
    "        f.close()\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = []\n",
    "for fname in csvs:\n",
    "    blob = f\"carbonplan-data/raw/fia/{fname.stem}.parquet\"\n",
    "    print(fname.stem)\n",
    "\n",
    "    if \"TREE.csv\" in str(fname):\n",
    "        continue\n",
    "\n",
    "    if exists(blob):\n",
    "        continue\n",
    "\n",
    "    df = force_float32(fname)\n",
    "\n",
    "    print(blob)\n",
    "\n",
    "    try:\n",
    "        df.to_parquet(\n",
    "            blob,\n",
    "            compression=\"gzip\",\n",
    "            open_with=fs.open,\n",
    "            row_group_offsets=1000,\n",
    "            engine=\"fastparquet\",\n",
    "        )\n",
    "        # consider using dask dataframe here to write to chunked dataframes here.\n",
    "        print(\"  --> \", blob)\n",
    "    except Exception as e:\n",
    "        failed.append((fname, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TREE.csv is a special case\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "row_group_offsets = 1000\n",
    "dtype = {\n",
    "    \"AGENTCD\": \"float64\",\n",
    "    \"CULL\": \"float64\",\n",
    "    \"P2A_GRM_FLG\": \"object\",\n",
    "    \"TREECLCD\": \"float64\",\n",
    "    \"TREEHISTCD\": \"float64\",\n",
    "    \"MODIFIED_IN_INSTANCE\": \"float64\",\n",
    "    \"GST_PNWRS\": \"object\",\n",
    "    \"SPGRPCD\": \"float64\",\n",
    "    \"DIAHTCD\": \"float64\",\n",
    "    \"SUBCYCLE\": \"float64\",\n",
    "    \"CAVITY_USE_PNWRS\": \"object\",\n",
    "}\n",
    "\n",
    "blob = \"TREE.parquet\"\n",
    "\n",
    "df = dd.read_csv(\n",
    "    \"/Users/jhamman/workdir/carbonplan_data_downloads/fia/ENTIRE/TREE.csv\",\n",
    "    dtype=dtype,\n",
    ")\n",
    "\n",
    "df.to_parquet(\"gs://carbonplan-data/raw/fia/TREE.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
