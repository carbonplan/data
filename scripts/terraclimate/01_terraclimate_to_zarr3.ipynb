{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"50\" src=\"https://carbonplan-assets.s3.amazonaws.com/monogram/dark-small.png\" style=\"margin-left:0px;margin-top:20px\"/>\n",
    "\n",
    "# TERRACLIMATE to Zarr\n",
    "\n",
    "_by Joe Hamman (CarbonPlan), June 29, 2020_\n",
    "\n",
    "This notebook converts the raw TERAACLIMATE dataset to Zarr format.\n",
    "\n",
    "**Inputs:**\n",
    "\n",
    "- inake catalog: `climate.gridmet_opendap`\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "- Cloud copy of TERRACLIMATE\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "- No reprojection or processing of the data is done in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fsspec\n",
    "import xarray as xr\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "from dask_gateway import Gateway\n",
    "from typing import List\n",
    "import urlpath\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "name = \"terraclimate\"\n",
    "chunks = {\"lat\": 1440, \"lon\": 1440, \"time\": 12}\n",
    "years = list(range(1958, 2020))\n",
    "cache_location = f\"gs://carbonplan-scratch/{name}-cache/\"\n",
    "target_location = f\"gs://carbonplan-data/raw/{name}/4000m/raster.zarr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67beb659d7a412eb53e1df52805c159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>GatewayCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n<style scoped>\\n    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gateway = Gateway()\n",
    "options = gateway.cluster_options()\n",
    "options.worker_cores = 1\n",
    "options.worker_memory = 42\n",
    "cluster = gateway.new_cluster(cluster_options=options)\n",
    "cluster.adapt(minimum=0, maximum=40)\n",
    "client = cluster.get_client()\n",
    "cluster\n",
    "# client = Client(n_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>gateway://traefik-gcp-us-central1-b-prod-dask-gateway.prod:80/prod.e1126ed4845145b5a031b4c9f9935b0d</li>\n",
       "  <li><b>Dashboard: </b><a href='https://gcp-us-central1b.hub.carbonplan.org/services/dask-gateway/clusters/prod.e1126ed4845145b5a031b4c9f9935b0d/status' target='_blank'>https://gcp-us-central1b.hub.carbonplan.org/services/dask-gateway/clusters/prod.e1126ed4845145b5a031b4c9f9935b0d/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tls://10.40.3.55:8786' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "try:\n",
    "    _ = fs.rm(target_location, recursive=True)\n",
    "except FileNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to remove all temporary zarr stores\n",
    "# zarrs = [fn + '.zarr' for fn in fs.glob('carbonplan-scratch/terraclimate-cache/*nc')]\n",
    "# fs.rm(zarrs, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    \"aet\",\n",
    "    \"def\",\n",
    "    \"pet\",\n",
    "    \"ppt\",\n",
    "    \"q\",\n",
    "    \"soil\",\n",
    "    \"srad\",\n",
    "    \"swe\",\n",
    "    \"tmax\",\n",
    "    \"tmin\",\n",
    "    \"vap\",\n",
    "    \"ws\",\n",
    "    \"vpd\",\n",
    "    \"PDSI\",\n",
    "]\n",
    "\n",
    "rename_vars = {'PDSI': 'pdsi'}\n",
    "\n",
    "mask_opts = {\n",
    "    \"PDSI\": (\"lt\", 10),\n",
    "    \"aet\": (\"lt\", 32767),\n",
    "    \"def\": (\"lt\", 32767),\n",
    "    \"pet\": (\"lt\", 32767),\n",
    "    \"ppt\": (\"lt\", 32767),\n",
    "    \"ppt_station_influence\": None,\n",
    "    \"q\": (\"lt\", 2147483647),\n",
    "    \"soil\": (\"lt\", 32767),\n",
    "    \"srad\": (\"lt\", 32767),\n",
    "    \"swe\": (\"lt\", 10000),\n",
    "    \"tmax\": (\"lt\", 200),\n",
    "    \"tmax_station_influence\": None,\n",
    "    \"tmin\": (\"lt\", 200),\n",
    "    \"tmin_station_influence\": None,\n",
    "    \"vap\": (\"lt\", 300),\n",
    "    \"vap_station_influence\": None,\n",
    "    \"vpd\": (\"lt\", 300),\n",
    "    \"ws\": (\"lt\", 200),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(key, da):\n",
    "    \"\"\"helper function to mask DataArrays based on a threshold value\"\"\"\n",
    "    if mask_opts.get(key, None):\n",
    "        op, val = mask_opts[key]\n",
    "        if op == \"lt\":\n",
    "            da = da.where(da < val)\n",
    "        elif op == \"neq\":\n",
    "            da = da.where(da != val)\n",
    "    return da\n",
    "\n",
    "\n",
    "def preproc(ds):\n",
    "    \"\"\"custom preprocessing function for terraclimate data\"\"\"\n",
    "    rename = {}\n",
    "\n",
    "    station_influence = ds.get(\"station_influence\", None)\n",
    "\n",
    "    if station_influence is not None:\n",
    "        ds = ds.drop_vars(\"station_influence\")\n",
    "\n",
    "    var = list(ds.data_vars)[0]\n",
    "\n",
    "    if var in rename_vars:\n",
    "        rename[var] = rename_vars[var]\n",
    "\n",
    "    if \"day\" in ds.coords:\n",
    "        rename[\"day\"] = \"time\"\n",
    "\n",
    "    if station_influence is not None:\n",
    "        ds[f\"{var}_station_influence\"] = station_influence\n",
    "\n",
    "    if rename:\n",
    "        ds = ds.rename(rename)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def postproc(ds):\n",
    "    \"\"\"custom post processing function to clean up terraclimate data\"\"\"\n",
    "    drop_encoding = [\n",
    "        \"chunksizes\",\n",
    "        \"fletcher32\",\n",
    "        \"shuffle\",\n",
    "        \"zlib\",\n",
    "        \"complevel\",\n",
    "        \"dtype\",\n",
    "        \"_Unsigned\",\n",
    "        \"missing_value\",\n",
    "        \"_FillValue\",\n",
    "        \"scale_factor\",\n",
    "        \"add_offset\",\n",
    "    ]\n",
    "    for v in ds.data_vars.keys():\n",
    "        with xr.set_options(keep_attrs=True):\n",
    "            ds[v] = apply_mask(v, ds[v])\n",
    "        for k in drop_encoding:\n",
    "            ds[v].encoding.pop(k, None)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def get_encoding(ds):\n",
    "    compressor = Blosc()\n",
    "    encoding = {key: {\"compressor\": compressor} for key in ds.data_vars}\n",
    "    return encoding\n",
    "\n",
    "\n",
    "@dask.delayed\n",
    "def download(source_url: str, cache_location: str) -> str:\n",
    "    \"\"\"\n",
    "    Download a remote file to a cache.\n",
    "    Parameters\n",
    "    ----------\n",
    "    source_url : str\n",
    "        Path or url to the source file.\n",
    "    cache_location : str\n",
    "        Path or url to the target location for the source file.\n",
    "    Returns\n",
    "    -------\n",
    "    target_url : str\n",
    "        Path or url in the form of `{cache_location}/hash({source_url})`.\n",
    "    \"\"\"\n",
    "    fs = fsspec.get_filesystem_class(cache_location.split(':')[0])(token='cloud')\n",
    "\n",
    "    name = urlpath.URL(source_url).name\n",
    "    target_url = os.path.join(cache_location, name)\n",
    "\n",
    "    # there is probably a better way to do caching!\n",
    "    try:\n",
    "        fs.open(target_url)\n",
    "        return target_url\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    with fsspec.open(source_url, mode=\"rb\") as source:\n",
    "        with fs.open(target_url, mode=\"wb\") as target:\n",
    "            target.write(source.read())\n",
    "    return target_url\n",
    "\n",
    "\n",
    "@dask.delayed(pure=True, traverse=False)\n",
    "def nc2zarr(source_url: str, cache_location: str) -> str:\n",
    "    \"\"\"convert netcdf data to zarr\"\"\"\n",
    "    fs = fsspec.get_filesystem_class(source_url.split(':')[0])(token='cloud')\n",
    "\n",
    "    target_url = source_url + \".zarr\"\n",
    "    \n",
    "    if fs.exists(urlpath.URL(target_url) / '.zgroup'):\n",
    "        return target_url\n",
    "\n",
    "    with dask.config.set(scheduler=\"single-threaded\"):\n",
    "\n",
    "        ds = (\n",
    "            xr.open_dataset(fs.open(source_url))\n",
    "            .pipe(preproc)\n",
    "            .pipe(postproc)\n",
    "            .load()\n",
    "            .chunk(chunks)\n",
    "        )\n",
    "\n",
    "        mapper = fs.get_mapper(target_url)\n",
    "        ds.to_zarr(mapper, mode='w')\n",
    "\n",
    "    return target_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://climate.northwestknowledge.net/TERRACLIMATE-DATA/TerraClimate_aet_1958.nc',\n",
       " 'https://climate.northwestknowledge.net/TERRACLIMATE-DATA/TerraClimate_aet_1959.nc',\n",
       " 'https://climate.northwestknowledge.net/TERRACLIMATE-DATA/TerraClimate_aet_1960.nc',\n",
       " 'https://climate.northwestknowledge.net/TERRACLIMATE-DATA/TerraClimate_aet_1961.nc']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_url_pattern = \"https://climate.northwestknowledge.net/TERRACLIMATE-DATA/TerraClimate_{var}_{year}.nc\"\n",
    "source_urls = []\n",
    "\n",
    "for var in variables:\n",
    "    for year in years:\n",
    "        source_urls.append(source_url_pattern.format(var=var, year=year))\n",
    "source_urls[:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloads = [download(s, cache_location) for s in source_urls]\n",
    "\n",
    "download_futures = client.compute(downloads, retries=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://carbonplan-scratch/terraclimate-cache/TerraClimate_aet_1958.nc',\n",
       " 'gs://carbonplan-scratch/terraclimate-cache/TerraClimate_aet_1959.nc',\n",
       " 'gs://carbonplan-scratch/terraclimate-cache/TerraClimate_aet_1960.nc',\n",
       " 'gs://carbonplan-scratch/terraclimate-cache/TerraClimate_aet_1961.nc']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downloaded_files = [d.result() for d in download_futures]\n",
    "downloaded_files[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarrs = [nc2zarr(s, cache_location) for s in downloaded_files]\n",
    "zarr_futures = client.compute(zarrs, retries=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - WARNING - Couldn't gather 1 keys, rescheduling {'nc2zarr-56e7ecbb07377b74cc237a521a258d1a': ('tls://10.40.174.4:32803',)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gs://carbonplan-scratch/terraclimate-cache/TerraClimate_aet_1958.nc.zarr',\n",
       " 'gs://carbonplan-scratch/terraclimate-cache/TerraClimate_aet_1959.nc.zarr',\n",
       " 'gs://carbonplan-scratch/terraclimate-cache/TerraClimate_aet_1960.nc.zarr',\n",
       " 'gs://carbonplan-scratch/terraclimate-cache/TerraClimate_aet_1961.nc.zarr']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zarr_urls = [d.result() for d in zarr_futures]\n",
    "zarr_urls[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [01:36<00:00,  1.56s/it]\n",
      "  0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat aet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [01:35<00:00,  1.55s/it]\n",
      "  0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat def\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "  0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat pet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [01:45<00:00,  1.70s/it]\n",
      "  0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat ppt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [01:36<00:00,  1.55s/it]\n",
      "  0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [01:34<00:00,  1.52s/it]\n",
      "  0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat soil\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [01:39<00:00,  1.60s/it]\n",
      "  0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat srad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [01:35<00:00,  1.55s/it]\n",
      "  0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat swe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [01:45<00:00,  1.71s/it]\n",
      "  0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat tmax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [01:47<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat tmin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [01:46<00:00,  1.72s/it]\n",
      "  0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat vap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [01:42<00:00,  1.65s/it]\n",
      "  0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [01:38<00:00,  1.59s/it]\n",
      "  0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat vpd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [01:37<00:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat PDSI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds_list = []\n",
    "for var in variables:\n",
    "    temp = []\n",
    "    for year in tqdm(years):\n",
    "        mapper = fsspec.get_mapper(f'gs://carbonplan-scratch/terraclimate-cache/TerraClimate_{var}_{year}.nc.zarr')\n",
    "        temp.append(xr.open_zarr(mapper))\n",
    "    print(f'concat {var}')\n",
    "    ds_list.append(xr.concat(temp, dim='time', coords='minimal', compat='override'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d6e5992f0bd49cfa6e0b84c6d8502cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>GatewayCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n<style scoped>\\n    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client.close()\n",
    "cluster.close()\n",
    "\n",
    "options.worker_cores = 4\n",
    "options.worker_memory = 16\n",
    "cluster = gateway.new_cluster(cluster_options=options)\n",
    "cluster.adapt(minimum=1, maximum=40)\n",
    "client = cluster.get_client()\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "ds = xr.merge(ds_list, compat='override').chunk(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zarr.hierarchy.Group '/'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 10.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "concurrent.futures._base.CancelledError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.7/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.7/ssl.py\", line 1139, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "OSError: [Errno 0] Error\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.7/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.7/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.7/site-packages/tornado/iostream.py\", line 1429, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.7/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.7/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "concurrent.futures._base.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.7/site-packages/tornado/iostream.py\", line 732, in _handle_events\n",
      "    self.close(exc_info=e)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.7/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.7/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "concurrent.futures._base.CancelledError\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mapper = fsspec.get_mapper(target_location)\n",
    "task = ds.to_zarr(mapper, mode=\"w\", compute=False)\n",
    "client.compute(task, retries=2)\n",
    "zarr.consolidate_metadata(mapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
